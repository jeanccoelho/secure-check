# ğŸ¤– IntegraÃ§Ã£o com Ollama - SecurityChecker AI

## ğŸ“‹ VisÃ£o Geral

O SecurityChecker agora possui uma versÃ£o AI-powered que utiliza o Ollama para anÃ¡lise inteligente de vulnerabilidades. Esta integraÃ§Ã£o permite:

- ğŸ§  **AnÃ¡lise contextual** do sistema usando IA
- ğŸ” **DetecÃ§Ã£o dinÃ¢mica** de vulnerabilidades especÃ­ficas
- ğŸ“Š **Coleta abrangente** de dados do sistema
- ğŸ¯ **CorreÃ§Ãµes personalizadas** para cada ambiente

## ğŸš€ Como Funciona

### 1. **Coleta de Dados**
O sistema coleta informaÃ§Ãµes detalhadas:
- VersÃ£o e configuraÃ§Ã£o do OS
- ServiÃ§os em execuÃ§Ã£o
- Portas de rede abertas
- Contas de usuÃ¡rio
- ConfiguraÃ§Ãµes de seguranÃ§a
- Processos ativos

### 2. **AnÃ¡lise IA**
Os dados sÃ£o enviados para o Ollama com um prompt especializado que:
- Analisa o contexto completo do sistema
- Identifica vulnerabilidades especÃ­ficas
- Gera correÃ§Ãµes personalizadas
- Classifica por severidade

### 3. **Resultados Estruturados**
A IA retorna vulnerabilidades em formato JSON:
```json
{
  "vulnerabilities": [
    {
      "id": "OLLAMA_VULN_001",
      "name": "SSH Root Login Habilitado",
      "description": "O SSH permite login direto como root",
      "impact": "Acesso total ao sistema via forÃ§a bruta",
      "severity": "Alta",
      "fix": "sed -i 's/^PermitRootLogin.*/PermitRootLogin no/' /etc/ssh/sshd_config && systemctl restart sshd"
    }
  ]
}
```

## âš™ï¸ ConfiguraÃ§Ã£o

### 1. **Instalar Ollama**
```bash
# Linux/macOS
curl -fsSL https://ollama.ai/install.sh | sh

# Windows
# Baixar de: https://ollama.ai/download
```

### 2. **Baixar Modelo**
```bash
# Modelo recomendado
ollama pull llama3.1

# Modelos alternativos
ollama pull codellama
ollama pull mistral
```

### 3. **Iniciar Servidor**
O SecurityChecker estÃ¡ configurado para usar o endpoint remoto:
```
https://ollama.annabank.com.br
```

### 4. **Configurar no SecurityChecker**
1. Marque "Usar anÃ¡lise com IA"
2. Clique em "âš™ï¸ Configurar"
3. Configure:
   - **Endpoint**: `https://ollama.annabank.com.br`
   - **Modelo**: `llama3.1`

## ğŸ¯ Uso

### **Modo Tradicional vs IA**

#### **Modo Tradicional:**
- âœ… VerificaÃ§Ãµes prÃ©-definidas
- âœ… RÃ¡pido e confiÃ¡vel
- âœ… Funciona offline
- âŒ Limitado a vulnerabilidades conhecidas

#### **Modo IA (Ollama):**
- âœ… AnÃ¡lise contextual inteligente
- âœ… DetecÃ§Ã£o de vulnerabilidades Ãºnicas
- âœ… CorreÃ§Ãµes personalizadas
- âœ… AdaptÃ¡vel a novos cenÃ¡rios
- âŒ Requer conexÃ£o com Ollama
- âŒ Mais lento (anÃ¡lise complexa)

### **Fluxo de Uso:**

1. **Ativar Modo IA**: Marque a checkbox "Usar anÃ¡lise com IA"
2. **Configurar**: Defina endpoint e modelo do Ollama
3. **Analisar**: Clique em "ğŸ” Analisar com IA"
4. **Aguardar**: O sistema coleta dados e envia para IA
5. **Revisar**: Analise as vulnerabilidades encontradas
6. **Corrigir**: Aplique as correÃ§Ãµes sugeridas

## ğŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas

### **Modelos Recomendados:**

| Modelo | Tamanho | Velocidade | Qualidade | Uso |
|--------|---------|------------|-----------|-----|
| `llama3.1` | ~4GB | MÃ©dia | Alta | **Recomendado** |
| `codellama` | ~3.8GB | RÃ¡pida | Boa | AnÃ¡lise tÃ©cnica |
| `mistral` | ~4.1GB | MÃ©dia | Alta | Alternativa |
| `llama3.1:70b` | ~40GB | Lenta | Excelente | Servidores potentes |

### **ParÃ¢metros de ConfiguraÃ§Ã£o:**

```cpp
OllamaConfig config;
config.endpoint = "http://localhost:11434";  // URL do servidor
config.model = "llama3.1";                   // Modelo a usar
config.timeout = 30000;                      // Timeout em ms
config.enabled = true;                       // Habilitar IA
```

### **ConfiguraÃ§Ã£o de Rede:**

O SecurityChecker usa por padrÃ£o o endpoint remoto da AnnaBank:
```bash
# Endpoint configurado
https://ollama.annabank.com.br

# Para usar endpoint local (se necessÃ¡rio):
# Endpoint: http://localhost:11434
```

## ğŸ› SoluÃ§Ã£o de Problemas

### **Erro: "ConexÃ£o recusada"**
```bash
# Verificar conectividade com o endpoint
curl -I https://ollama.annabank.com.br

# Verificar se o modelo estÃ¡ disponÃ­vel
curl https://ollama.annabank.com.br/api/tags
```

### **Erro: "Modelo nÃ£o encontrado"**
```bash
# Listar modelos instalados
ollama list

# Instalar modelo necessÃ¡rio
ollama pull llama3.1
```

### **Erro: "Timeout na requisiÃ§Ã£o"**
- Aumentar timeout na configuraÃ§Ã£o
- Usar modelo menor/mais rÃ¡pido
- Verificar recursos do sistema

### **Resposta invÃ¡lida da IA**
- Modelo pode estar sobrecarregado
- Tentar novamente
- Usar modelo diferente

## ğŸ“Š ComparaÃ§Ã£o de Performance

### **Tempo de AnÃ¡lise (aproximado):**

| Sistema | Modo Tradicional | Modo IA |
|---------|------------------|---------|
| Linux bÃ¡sico | ~30 segundos | ~2-5 minutos |
| Windows completo | ~45 segundos | ~3-7 minutos |
| macOS | ~35 segundos | ~2-4 minutos |

### **Recursos NecessÃ¡rios:**

| Componente | Tradicional | IA (llama3.1) |
|------------|-------------|---------------|
| RAM | ~100MB | ~4-6GB |
| CPU | Baixo | Alto |
| Rede | NÃ£o | Sim (local) |
| Armazenamento | ~50MB | ~4GB+ |

## ğŸ”’ SeguranÃ§a e Privacidade

### **Dados Enviados para IA:**
- âœ… InformaÃ§Ãµes de configuraÃ§Ã£o do sistema
- âœ… Lista de serviÃ§os e processos
- âœ… ConfiguraÃ§Ãµes de seguranÃ§a
- âŒ **NÃƒO** envia dados pessoais
- âŒ **NÃƒO** envia conteÃºdo de arquivos
- âŒ **NÃƒO** envia senhas ou chaves

### **Processamento Local:**
- ğŸ  Toda anÃ¡lise Ã© feita **localmente**
- ğŸ”’ Nenhum dado sai da sua rede
- ğŸ›¡ï¸ Ollama roda em sua mÃ¡quina
- ğŸ” Controle total sobre os dados

## ğŸš€ PrÃ³ximas Funcionalidades

### **Em Desenvolvimento:**
- ğŸ“ˆ **AnÃ¡lise de tendÃªncias** de seguranÃ§a
- ğŸ”„ **Monitoramento contÃ­nuo** com IA
- ğŸ“Š **RelatÃ³rios inteligentes** personalizados
- ğŸ¯ **RecomendaÃ§Ãµes proativas** de seguranÃ§a
- ğŸŒ **IntegraÃ§Ã£o com feeds** de vulnerabilidades

### **Roadmap:**
- **v1.1**: AnÃ¡lise de logs com IA
- **v1.2**: DetecÃ§Ã£o de anomalias comportamentais
- **v1.3**: IntegraÃ§Ã£o com CVE databases
- **v1.4**: AnÃ¡lise de compliance automatizada

## ğŸ’¡ Dicas de Uso

### **Para Melhor Performance:**
1. Use SSD para armazenar modelos Ollama
2. Tenha pelo menos 8GB RAM disponÃ­vel
3. Use CPU com mÃºltiplos cores
4. Feche aplicaÃ§Ãµes desnecessÃ¡rias durante anÃ¡lise

### **Para Melhor Qualidade:**
1. Use modelos maiores quando possÃ­vel
2. ForneÃ§a contexto adicional se necessÃ¡rio
3. Execute anÃ¡lises em sistemas "limpos"
4. Mantenha Ollama atualizado

### **Para Uso Empresarial:**
1. Configure Ollama em servidor dedicado
2. Use modelos especializados em seguranÃ§a
3. Implemente cache de resultados
4. Configure monitoramento de recursos

---

**ğŸ¤– SecurityChecker AI** - Democratizando a seguranÃ§a digital com inteligÃªncia artificial! ğŸ›¡ï¸